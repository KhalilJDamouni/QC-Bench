{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0fd767f124e7d2a8bdccf6b13662be2ce8b3fa3799521e7d6ac19ad88bc5cbd58",
   "display_name": "Python 3.9.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import statistics as stat\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import wraps\n",
    "from contextlib import contextmanager, _GeneratorContextManager\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
    "        in_features = base.fc.in_features\n",
    "        self.drop = nn.Dropout()\n",
    "        self.final = nn.Linear(in_features,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.base(x)\n",
    "        x = self.drop(x.view(-1,self.final.in_features))\n",
    "        return self.final(x)\n",
    "    \n",
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Loading everything\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def _perturbed_model(\n",
    "  model,\n",
    "  sigma: float = 1,\n",
    "  rng = torch.Generator(),\n",
    "  magnitude_eps = None\n",
    "):\n",
    "  device = next(model.parameters()).device\n",
    "  if magnitude_eps is not None:\n",
    "    noise = [torch.normal(0,sigma**2 * torch.abs(p) ** 2 + magnitude_eps ** 2, generator=rng) for p in model.parameters()]\n",
    "  else:\n",
    "    noise = [torch.normal(0,sigma**2,p.shape, generator=rng).to(device) for p in model.parameters()]\n",
    "  model = deepcopy(model)\n",
    "  try:\n",
    "    [p.add_(n) for p,n in zip(model.parameters(), noise)]\n",
    "    yield model\n",
    "  finally:\n",
    "    [p.sub_(n) for p,n in zip(model.parameters(), noise)]\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pacbayes_sigma(\n",
    "  model,\n",
    "  dataloader,\n",
    "  accuracy: float,\n",
    "  seed: int,\n",
    "  magnitude_eps = None,\n",
    "  search_depth: int = 15,\n",
    "  montecarlo_samples: int = 10,\n",
    "  accuracy_displacement: float = 0.1,\n",
    "  displacement_tolerance: float = 1e-2,\n",
    ") -> float:\n",
    "  lower, upper = 0, 2\n",
    "  sigma = 1\n",
    "\n",
    "  BIG_NUMBER = 10348628753\n",
    "  device = next(model.parameters()).device\n",
    "  rng = torch.Generator(device=device) if magnitude_eps is not None else torch.Generator()\n",
    "  rng.manual_seed(BIG_NUMBER + seed)\n",
    "\n",
    "  for _ in range(search_depth):\n",
    "    sigma = (lower + upper) / 2\n",
    "    accuracy_samples = []\n",
    "    for _ in range(montecarlo_samples):\n",
    "      with _perturbed_model(model, sigma, rng, magnitude_eps) as p_model:\n",
    "        loss_estimate = 0\n",
    "        for data, target in dataloader:\n",
    "          logits = p_model(data.cuda())\n",
    "          pred = logits.data.max(1, keepdim=True)[1]  # get the index of the max logits\n",
    "          batch_correct = pred.eq(target.data.view_as(pred)).type(torch.FloatTensor).cpu()\n",
    "          loss_estimate += batch_correct.sum()\n",
    "        loss_estimate /= len(dataloader.dataset)\n",
    "        accuracy_samples.append(loss_estimate)\n",
    "    displacement = abs(np.mean(accuracy_samples) - accuracy)\n",
    "    if abs(displacement - accuracy_displacement) < displacement_tolerance:\n",
    "      break\n",
    "    elif displacement > accuracy_displacement:\n",
    "      # Too much perturbation\n",
    "      upper = sigma\n",
    "    else:\n",
    "      # Not perturbed enough to reach target displacement\n",
    "      lower = sigma\n",
    "  return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main:\n",
    "def main():\n",
    "    model.eval()\n",
    "\n",
    "    #Calculates Model Accuracy\n",
    "    cross_entropy_loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    data_loader = [trainloader, testloader][0] #0 for Train, 1 for Test\n",
    "    num_to_evaluate_on = len(data_loader.dataset)\n",
    "\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        logits = model(data)\n",
    "        cross_entropy = F.cross_entropy(logits, target, reduction='sum')\n",
    "        cross_entropy_loss += cross_entropy.item()  # sum up batch loss\n",
    "        \n",
    "        pred = logits.data.max(1, keepdim=True)[1]  # get the index of the max logits\n",
    "        batch_correct = pred.eq(target.data.view_as(pred)).type(torch.FloatTensor).cpu()\n",
    "        num_correct += batch_correct.sum()\n",
    "\n",
    "    cross_entropy_loss /= num_to_evaluate_on\n",
    "    acc = num_correct.item() / num_to_evaluate_on #Get acc for sigma\n",
    "\n",
    "    return cross_entropy_loss, acc, num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run():\n",
    "    cross_entropy_loss, acc, num_correct = main()\n",
    "    sigma = _pacbayes_sigma(model, testloader, acc, seed)\n",
    "    flattness = torch.tensor(1 / sigma ** 2)\n",
    "    print(flatness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-aa4c47973f78>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pacbayes_sigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mflattness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-7c9f15d8ee9e>\u001b[0m in \u001b[0;36m_pacbayes_sigma\u001b[1;34m(model, dataloader, accuracy, seed, magnitude_eps, search_depth, montecarlo_samples, accuracy_displacement, displacement_tolerance)\u001b[0m\n\u001b[0;32m     27\u001b[0m           \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m           \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# get the index of the max logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m           \u001b[0mbatch_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m           \u001b[0mloss_estimate\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_correct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloss_estimate\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}