{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ab71728b2e6544376d0f7b7ce3a2690cdf3a078b6ef92caeda64ccdf9bfd26c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from scipy import stats\n",
    "import math\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def agg(x, L, a=[]):\n",
    "    if(L == 1):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return np.average(np.abs(x),weights=a,axis=1)\n",
    "    if(L == 2):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return LA.norm(x,axis=1)/np.sqrt(np.sum(a,axis=1))\n",
    "    if(L == 3):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return np.prod(np.power(x,a/np.repeat(np.expand_dims(np.sum(a,axis=1),axis=1),a.shape[1],axis=1)),axis=1)\n",
    "    if(L == 4):\n",
    "        a = a*np.logical_not(ma.getmaskarray(x))\n",
    "        return np.average(np.abs(x),weights=a,axis=1)\n",
    "    if(L == 5):\n",
    "        a = a*np.logical_not(ma.getmaskarray(x))\n",
    "        return np.prod(np.power(x,a/np.repeat(np.expand_dims(np.sum(a,axis=1),axis=1),a.shape[1],axis=1)),axis=1)\n",
    "\n",
    "def all_aggs(in_chan, out_chan, in_weight, out_weight):\n",
    "    return np.asarray([agg(np.ma.concatenate((in_chan,out_chan),axis=1),L=i,a=np.ma.concatenate((in_weight,out_weight),axis=1)) for i in range(1,6)])\n",
    "\n",
    "def sqrtlog(chans, weights):\n",
    "    a = np.logical_not(ma.getmaskarray(weights))\n",
    "    all = []\n",
    "    for i in range(len(chans)):\n",
    "        all.append([])\n",
    "        chand = chans[i]*np.sum(a,axis=1)\n",
    "        all[i].append(chans[i])\n",
    "        all[i].append(chand)\n",
    "        all[i].append(np.sqrt(chans[i]))\n",
    "        all[i].append(np.sqrt(chand))\n",
    "        all[i].append(np.log(chans[i]))\n",
    "        all[i].append(np.log(chand))\n",
    "        all[i].append(np.log(np.sqrt(chans[i])))\n",
    "        all[i].append(np.log(np.sqrt(chand)))\n",
    "    return all\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv(filename,skip_blank_lines=False)\n",
    "    data = dict()\n",
    "\n",
    "    if(pd.isna(df.iloc[-1][1])):\n",
    "        df = df.drop(labels=df.shape[0]-1, axis=0)\n",
    "\n",
    "    zero_models = []\n",
    "\n",
    "    idx = list(np.where(pd.isna(df[\"model_id\"]))[0])\n",
    "    idxcopy = idx\n",
    "    idx = idx - np.arange(0,len(idx),1)\n",
    "    lenidx = np.append(idx,len(df[\"model_id\"])-len(idx))\n",
    "    lenidx = np.insert(lenidx,0,0)\n",
    "    maxLength = np.max(np.abs(np.diff(lenidx)))\n",
    "    for key in list(df.keys()):\n",
    "        idxx = list(np.where(pd.isna(df[key]))[0])\n",
    "        idxx = list(set(idxcopy) ^ set(idxx))\n",
    "        data[key] = df[key]\n",
    "        datacopy = data[key]\n",
    "        data[key].loc[idxx] = 0\n",
    "        data[key] = data[key].dropna(axis=0)\n",
    "        data[key] = np.array_split(data[key],idx)\n",
    "    \n",
    "        for i in range(len(data[key])):\n",
    "            #equalize all model sizes\n",
    "            prevlen = len(data[key][i])\n",
    "            data[key][i] = np.append(data[key][i],(np.zeros((maxLength-len(data[key][i])))))\n",
    "            #delete zero models\n",
    "            num_non_zero = np.sum(data[key][i]!=0)\n",
    "            threshold = 1\n",
    "            if(num_non_zero<threshold):\n",
    "                #print(key,str(i),num_non_zero,prevlen)\n",
    "                zero_models.append(i)\n",
    "        data[key] = np.asarray(data[key])\n",
    "    \n",
    "    zero_models = list(set(zero_models))\n",
    "    print(\"zero models deleted: \"+str(len(zero_models)))\n",
    "    for key in list(data.keys()):\n",
    "        data[key] = np.delete(data[key],zero_models,axis=0)\n",
    "        data[key] = ma.masked_array(data[key], mask=(data[key]==0.))\n",
    "\n",
    "    data['in_QS_BE'] = np.arctan2(data['in_S_BE'],(1-1/data['in_C_BE']))\n",
    "    data['out_QS_BE'] = np.arctan2(data['out_S_BE'],(1-1/data['out_C_BE']))\n",
    "    data['in_QS_AE'] = np.arctan2(data['in_S_AE'],(1-1/data['in_C_AE']))\n",
    "    data['out_QS_AE'] = np.arctan2(data['out_S_AE'],(1-1/data['out_C_AE']))\n",
    "\n",
    "    aggregates = dict()\n",
    "\n",
    "    aggregates['QS_BE'] = all_aggs(data['in_QS_BE'],data['out_QS_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['QS_AE'] = all_aggs(data['in_QS_AE'],data['out_QS_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "    aggregates['QE_BE'] = all_aggs(data['in_ER_BE'],data['out_ER_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['QE_AE'] = all_aggs(data['in_ER_AE'],data['out_ER_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "\n",
    "    aggregates['QS_BE'] = sqrtlog(aggregates['QS_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['QS_AE'] = sqrtlog(aggregates['QS_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "    aggregates['QE_BE'] = sqrtlog(aggregates['QE_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['QE_AE'] = sqrtlog(aggregates['QE_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "\n",
    "    aggregates['spec_BE'] = all_aggs(data['in_spec_BE'],data['out_spec_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['spec_AE'] = all_aggs(data['in_spec_AE'],data['out_spec_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "    aggregates['fro_BE'] = all_aggs(data['in_fro_BE'],data['out_fro_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['fro_AE'] = all_aggs(data['in_fro_AE'],data['out_fro_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "\n",
    "    aggregates['spec_BE'] = sqrtlog(aggregates['spec_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['spec_AE'] = sqrtlog(aggregates['spec_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "    aggregates['fro_BE'] = sqrtlog(aggregates['fro_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['fro_AE'] = sqrtlog(aggregates['fro_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "\n",
    "    aggregates['path'] = np.mean(data['path'],axis=1)\n",
    "\n",
    "    aggregates['test_acc'] = np.mean(data['test_acc'],axis=1)\n",
    "    aggregates['train_acc'] = np.mean(data['train_acc'],axis=1)\n",
    "    aggregates['test_loss'] = np.mean(data['test_loss'],axis=1)\n",
    "    aggregates['train_loss'] = np.mean(data['train_loss'],axis=1)\n",
    "    aggregates['gap'] = np.mean(data['gap'],axis=1)\n",
    "\n",
    "    return aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "optimizer = ['AdaM','AdamP','AdaBound']\n",
    "\n",
    "epochs = []\n",
    "raw = [glob.glob(str(sys.path[0][0:-8])+\"/outputs/LilJon-\"+optimize+\"-\"+dataset+\"/*\") for optimize in optimizer]\n",
    "wanted_epochs = np.arange(0,70,5)\n",
    "wanted_epochs = np.append(wanted_epochs, 69)\n",
    "for i in range(len(wanted_epochs)):\n",
    "    epochs.append([])\n",
    "    for j in range(len(optimizer)):\n",
    "        for rawe in raw[j]:\n",
    "            if(int((rawe.split('-')[-1]).split('.')[0]) == wanted_epochs[i]):\n",
    "                epochs[i].append(rawe)\n",
    "\n",
    "translation = {'QS':'SQ','QE':'E','spec':'S','fro':'F'}\n",
    "fancytranslation = {'QS_AE':'${\\widehat{Q}_{SQ}^{p}}$','QE_AE':'${\\widehat{Q}_{E}^{L2}}$','spec_AE':'${\\widehat{Q}_{S}^{p}}$','fro_AE':'${\\widehat{Q}_{F}^{p}}$','QS_BE':'${{Q}_{SQ}^{p}}$','QE_BE':'${{Q}_{E}^{L2}}$','spec_BE':'${{Q}_{S}^{p}}$','fro_BE':'${{Q}_{F}^{p}}$'}\n",
    "types = {'QS':[2,0],'QE':[1,6],'spec':[2,7],'fro':[2,7]}\n",
    "lrfdict = {'AE':'LRF','BE':''}\n",
    "gendict = {'test_acc':'test','gap':'gap'}\n",
    "fancygendict = {'test_acc':'Test Acc.','gap':'Gen. Gap'}\n",
    "optimizer = '-'.join(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_19-48-38-LilJon-CIFAR10-0.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_14-52-09-LilJon-CIFAR10-0.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-0.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_21-10-08-LilJon-CIFAR10-5.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_16-10-58-LilJon-CIFAR10-5.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_21-46-38-LilJon-CIFAR10-5.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_20-01-29-LilJon-CIFAR10-10.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_14-55-48-LilJon-CIFAR10-10.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-10.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_00-45-05-LilJon-CIFAR10-15.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_16-58-47-LilJon-CIFAR10-15.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_22-57-41-LilJon-CIFAR10-15.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_20-52-43-LilJon-CIFAR10-20.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_17-14-17-LilJon-CIFAR10-20.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-20.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_23-17-33-LilJon-CIFAR10-25.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_20-54-52-LilJon-CIFAR10-25.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_21-27-27-LilJon-CIFAR10-25.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_23-23-39-LilJon-CIFAR10-30.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_17-36-23-LilJon-CIFAR10-30.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-30.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_01-14-19-LilJon-CIFAR10-35.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_19-51-49-LilJon-CIFAR10-35.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_22-42-00-LilJon-CIFAR10-35.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-05-2021_23-23-39-LilJon-CIFAR10-40.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_17-59-43-LilJon-CIFAR10-40.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-40.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_03-01-54-LilJon-CIFAR10-45.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_18-56-16-LilJon-CIFAR10-45.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_21-44-45-LilJon-CIFAR10-45.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_01-25-55-LilJon-CIFAR10-50.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_17-59-43-LilJon-CIFAR10-50.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-50.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_04-32-37-LilJon-CIFAR10-55.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_19-43-02-LilJon-CIFAR10-55.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_22-59-57-LilJon-CIFAR10-55.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_01-50-39-LilJon-CIFAR10-60.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_18-38-21-LilJon-CIFAR10-60.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_20-19-45-LilJon-CIFAR10-60.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_03-38-31-LilJon-CIFAR10-65.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_20-05-27-LilJon-CIFAR10-65.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_22-02-23-LilJon-CIFAR10-65.csv'], ['c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaM-CIFAR10\\\\results-07-06-2021_05-05-03-LilJon-CIFAR10-69.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdamP-CIFAR10\\\\results-07-08-2021_21-16-19-LilJon-CIFAR10-69.csv', 'c:\\\\Users\\\\jjaeg\\\\Desktop\\\\QC-Bench\\\\/outputs/LilJon-AdaBound-CIFAR10\\\\results-07-08-2021_23-13-52-LilJon-CIFAR10-69.csv']]\n"
     ]
    }
   ],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_19-48-38-LilJon-CIFAR10-0.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "0\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_21-10-08-LilJon-CIFAR10-5.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "16\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_20-01-29-LilJon-CIFAR10-10.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "32\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_00-45-05-LilJon-CIFAR10-15.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "48\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_20-52-43-LilJon-CIFAR10-20.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "64\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_23-17-33-LilJon-CIFAR10-25.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "80\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_23-23-39-LilJon-CIFAR10-30.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "96\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_01-14-19-LilJon-CIFAR10-35.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "112\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-05-2021_23-23-39-LilJon-CIFAR10-40.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "128\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_03-01-54-LilJon-CIFAR10-45.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "144\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_01-25-55-LilJon-CIFAR10-50.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "160\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_04-32-37-LilJon-CIFAR10-55.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "176\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_01-50-39-LilJon-CIFAR10-60.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "192\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_03-38-31-LilJon-CIFAR10-65.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "208\n",
      "c:\\Users\\jjaeg\\Desktop\\QC-Bench\\/outputs/LilJon-AdaM-CIFAR10\\results-07-06-2021_05-05-03-LilJon-CIFAR10-69.csv\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "zero models deleted: 15\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "for epoch in epochs:\n",
    "    print(epoch[0])\n",
    "    data = get_data(epoch[0])\n",
    "    for combine in epoch[1:]:\n",
    "        datac = get_data(combine)\n",
    "        for keye in data.keys():\n",
    "            if len((np.asarray(data[keye])).shape) < 2:\n",
    "                data[keye] = np.append(data[keye], datac[keye])\n",
    "            else:\n",
    "                for agge in range(len(data[keye])):\n",
    "                        for proe in range(8):\n",
    "                            data[keye][agge][proe] = np.append(data[keye][agge][proe], datac[keye][agge][proe])\n",
    "    print(i)\n",
    "    for key in translation.keys():\n",
    "        for lrf in lrfdict.keys():\n",
    "            for gen in gendict.keys():\n",
    "                plt.figure(figsize=(8.5, 8.5))\n",
    "                plt.locator_params(axis='y', nbins=6)\n",
    "                plt.locator_params(axis='x', nbins=6)\n",
    "                plt.plot(data[key+\"_\"+lrf][types[key][0]][types[key][1]],data[gen],'ro',alpha=0.5)\n",
    "                coefficients = np.polyfit(data[key+\"_\"+lrf][types[key][0]][types[key][1]],data[gen],2)\n",
    "                plt.plot(np.arange(min(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),max(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),0.001),np.polyval(coefficients,np.arange(min(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),max(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),0.001)), c='black', lw=4,alpha=0.85)\n",
    "                plt.xlabel(\"Quality Measure \"+fancytranslation[key+\"_\"+lrf],fontsize=34)\n",
    "                plt.ylabel(fancygendict[gen],fontsize=34)\n",
    "                plt.xticks(fontsize=28)\n",
    "                plt.yticks(fontsize=28)\n",
    "                plt.title(fancygendict[gen]+\" over \"+fancytranslation[key+\"_\"+lrf]+\" at Epoch \"+str(int((epoch[0].split('-')[-1]).split('.')[0])+1),fontsize=34)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(str(sys.path[0][0:-9])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/\"+gendict[gen]+\"/\"+lrfdict[lrf]+(epoch[0].split('-')[-1]).split('.')[0]+\".png\", bbox_inches=\"tight\")\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "                i+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "zero models deleted: 15\n",
      "10\n",
      "zero models deleted: 15\n",
      "20\n",
      "zero models deleted: 15\n",
      "30\n",
      "zero models deleted: 15\n",
      "40\n",
      "zero models deleted: 15\n",
      "50\n",
      "zero models deleted: 15\n",
      "60\n",
      "zero models deleted: 15\n",
      "25\n",
      "zero models deleted: 15\n",
      "45\n",
      "zero models deleted: 15\n",
      "5\n",
      "zero models deleted: 15\n",
      "65\n",
      "zero models deleted: 15\n",
      "35\n",
      "zero models deleted: 15\n",
      "15\n",
      "zero models deleted: 15\n",
      "55\n",
      "zero models deleted: 15\n",
      "69\n",
      "zero models deleted: 15\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"CIFAR10\"]:\n",
    "    for optimizer in [\"AdaBound\"]:\n",
    "        input_path = str(sys.path[0][0:-8])+\"/outputs/LilJon-\"+optimizer+\"-\"+dataset\n",
    "        epochs = glob.glob(input_path+\"/*\")\n",
    "        wanted_epochs = np.arange(0,70,5)\n",
    "        wanted_epochs = np.append(wanted_epochs, 69)\n",
    "\n",
    "        translation = {'QS':'SQ','QE':'E','spec':'S','fro':'F'}\n",
    "        fancytranslation = {'QS_AE':'${\\widehat{Q}_{SQ}^{p}}$','QE_AE':'${\\widehat{Q}_{E}^{L2}}$','spec_AE':'${\\widehat{Q}_{S}^{p}}$','fro_AE':'${\\widehat{Q}_{F}^{p}}$',   'QS_BE':'${{Q}_{SQ}^{p}}$','QE_BE':'${{Q}_{E}^{L2}}$','spec_BE':'${{Q}_{S}^{p}}$','fro_BE':'${{Q}_{F}^{p}}$'}\n",
    "        types = {'QS':[2,0],'QE':[1,6],'spec':[2,7],'fro':[2,7]}\n",
    "        lrfdict = {'AE':'LRF','BE':''}\n",
    "        gendict = {'test_acc':'test','gap':'gap'}\n",
    "        fancygendict = {'test_acc':'Test Acc.','gap':'Gen. Gap'}\n",
    "        for epoch in epochs:\n",
    "            if int((epoch.split('-')[-1]).split('.')[0]) in wanted_epochs:\n",
    "                print(int((epoch.split('-')[-1]).split('.')[0]))\n",
    "                data = get_data(epoch)\n",
    "                \n",
    "                for key in translation.keys():\n",
    "                    for lrf in lrfdict.keys():\n",
    "                        for gen in gendict.keys():\n",
    "                            plt.figure(figsize=(8.5, 8.5))\n",
    "                            plt.locator_params(axis='y', nbins=6)\n",
    "                            plt.locator_params(axis='x', nbins=6)\n",
    "                            plt.plot(data[key+\"_\"+lrf][types[key][0]][types[key][1]],data[gen],'ro',alpha=0.5)\n",
    "                            coefficients = np.polyfit(data[key+\"_\"+lrf][types[key][0]][types[key][1]],data[gen],2)\n",
    "                            plt.plot(np.arange(min(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),max(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),0.001),np.polyval(coefficients,np.arange(min(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),max(data[key+\"_\"+lrf][types[key][0]][types[key][1]]),0.001)), c='black', lw=4,alpha=0.85)\n",
    "                            plt.xlabel(\"Quality Measure \"+fancytranslation[key+\"_\"+lrf],fontsize=34)\n",
    "                            plt.ylabel(fancygendict[gen],fontsize=34)\n",
    "                            plt.xticks(fontsize=28)\n",
    "                            plt.yticks(fontsize=28)\n",
    "                            plt.title(fancygendict[gen]+\" over \"+fancytranslation[key+\"_\"+lrf]+\" at Epoch \"+str(int((epoch.split('-')[-1]).split('.')[0])+1),fontsize=34)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(str(sys.path[0][0:-9])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/\"+gendict[gen]+\"/\"+lrfdict[lrf]+(epoch.split('-')[-1]).split('.')[0]+\".png\", bbox_inches=\"tight\")\n",
    "                            plt.clf()\n",
    "                            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}