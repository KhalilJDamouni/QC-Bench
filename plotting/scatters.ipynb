{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ab71728b2e6544376d0f7b7ce3a2690cdf3a078b6ef92caeda64ccdf9bfd26c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from scipy import stats\n",
    "import math\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def agg(x, L, a=[]):\n",
    "    if(L == 1):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return np.average(np.abs(x),weights=a,axis=1)\n",
    "    if(L == 2):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return LA.norm(x,axis=1)/np.sqrt(np.sum(a,axis=1))\n",
    "    if(L == 3):\n",
    "        a = np.logical_not(ma.getmaskarray(x))\n",
    "        return np.prod(np.power(x,a/np.repeat(np.expand_dims(np.sum(a,axis=1),axis=1),a.shape[1],axis=1)),axis=1)\n",
    "    if(L == 4):\n",
    "        a = a*np.logical_not(ma.getmaskarray(x))\n",
    "        return np.average(np.abs(x),weights=a,axis=1)\n",
    "    if(L == 5):\n",
    "        a = a*np.logical_not(ma.getmaskarray(x))\n",
    "        return np.prod(np.power(x,a/np.repeat(np.expand_dims(np.sum(a,axis=1),axis=1),a.shape[1],axis=1)),axis=1)\n",
    "\n",
    "def all_aggs(in_chan, out_chan, in_weight, out_weight):\n",
    "    return np.asarray([agg(np.ma.concatenate((in_chan,out_chan),axis=1),L=i,a=np.ma.concatenate((in_weight,out_weight),axis=1)) for i in range(1,6)])\n",
    "\n",
    "def sqrtlog(chans, weights):\n",
    "    a = np.logical_not(ma.getmaskarray(weights))\n",
    "    all = []\n",
    "    for i in range(len(chans)):\n",
    "        all.append([])\n",
    "        chand = chans[i]*np.sum(a,axis=1)\n",
    "        all[i].append(chans[i])\n",
    "        all[i].append(chand)\n",
    "        all[i].append(np.sqrt(chans[i]))\n",
    "        all[i].append(np.sqrt(chand))\n",
    "        all[i].append(np.log(chans[i]))\n",
    "        all[i].append(np.log(chand))\n",
    "        all[i].append(np.log(np.sqrt(chans[i])))\n",
    "        all[i].append(np.log(np.sqrt(chand)))\n",
    "    return all\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pd.read_csv(filename,skip_blank_lines=False)\n",
    "    data = dict()\n",
    "\n",
    "    if(pd.isna(df.iloc[-1][1])):\n",
    "        df = df.drop(labels=df.shape[0]-1, axis=0)\n",
    "\n",
    "    zero_models = []\n",
    "\n",
    "    idx = list(np.where(pd.isna(df[\"model_id\"]))[0])\n",
    "    idxcopy = idx\n",
    "    idx = idx - np.arange(0,len(idx),1)\n",
    "    lenidx = np.append(idx,len(df[\"model_id\"])-len(idx))\n",
    "    lenidx = np.insert(lenidx,0,0)\n",
    "    maxLength = np.max(np.abs(np.diff(lenidx)))\n",
    "    for key in list(df.keys()):\n",
    "        idxx = list(np.where(pd.isna(df[key]))[0])\n",
    "        idxx = list(set(idxcopy) ^ set(idxx))\n",
    "        data[key] = df[key]\n",
    "        datacopy = data[key]\n",
    "        data[key].loc[idxx] = 0\n",
    "        data[key] = data[key].dropna(axis=0)\n",
    "        data[key] = np.array_split(data[key],idx)\n",
    "    \n",
    "        for i in range(len(data[key])):\n",
    "            #equalize all model sizes\n",
    "            prevlen = len(data[key][i])\n",
    "            data[key][i] = np.append(data[key][i],(np.zeros((maxLength-len(data[key][i])))))\n",
    "            #delete zero models\n",
    "            num_non_zero = np.sum(data[key][i]!=0)\n",
    "            threshold = 1\n",
    "            if(num_non_zero<threshold):\n",
    "                #print(key,str(i),num_non_zero,prevlen)\n",
    "                zero_models.append(i)\n",
    "        data[key] = np.asarray(data[key])\n",
    "    \n",
    "    zero_models = list(set(zero_models))\n",
    "    print(\"zero models deleted: \"+str(len(zero_models)))\n",
    "    for key in list(data.keys()):\n",
    "        data[key] = np.delete(data[key],zero_models,axis=0)\n",
    "        data[key] = ma.masked_array(data[key], mask=(data[key]==0.))\n",
    "\n",
    "    data['in_QS_BE'] = np.arctan2(data['in_S_BE'],(1-1/data['in_C_BE']))\n",
    "    data['out_QS_BE'] = np.arctan2(data['out_S_BE'],(1-1/data['out_C_BE']))\n",
    "    data['in_QS_AE'] = np.arctan2(data['in_S_AE'],(1-1/data['in_C_AE']))\n",
    "    data['out_QS_AE'] = np.arctan2(data['out_S_AE'],(1-1/data['out_C_AE']))\n",
    "\n",
    "    aggregates = dict()\n",
    "\n",
    "    aggregates['QS_BE'] = all_aggs(data['in_QS_BE'],data['out_QS_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['QS_AE'] = all_aggs(data['in_QS_AE'],data['out_QS_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "    aggregates['QE_BE'] = all_aggs(data['in_ER_BE'],data['out_ER_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['QE_AE'] = all_aggs(data['in_ER_AE'],data['out_ER_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "\n",
    "    aggregates['QS_BE'] = sqrtlog(aggregates['QS_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['QS_AE'] = sqrtlog(aggregates['QS_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "    aggregates['QE_BE'] = sqrtlog(aggregates['QE_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['QE_AE'] = sqrtlog(aggregates['QE_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "\n",
    "    aggregates['spec_BE'] = all_aggs(data['in_spec_BE'],data['out_spec_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['spec_AE'] = all_aggs(data['in_spec_AE'],data['out_spec_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "    aggregates['fro_BE'] = all_aggs(data['in_fro_BE'],data['out_fro_BE'],data['in_weight_BE'],data['out_weight_BE'])\n",
    "    aggregates['fro_AE'] = all_aggs(data['in_fro_AE'],data['out_fro_AE'],data['in_weight_AE'],data['out_weight_AE'])\n",
    "\n",
    "    aggregates['spec_BE'] = sqrtlog(aggregates['spec_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['spec_AE'] = sqrtlog(aggregates['spec_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "    aggregates['fro_BE'] = sqrtlog(aggregates['fro_BE'],np.ma.concatenate((data['in_weight_BE'],data['out_weight_BE']),axis=1))\n",
    "    aggregates['fro_AE'] = sqrtlog(aggregates['fro_AE'],np.ma.concatenate((data['in_weight_AE'],data['out_weight_AE']),axis=1))\n",
    "\n",
    "    aggregates['path'] = np.mean(data['path'],axis=1)\n",
    "\n",
    "    aggregates['test_acc'] = np.mean(data['test_acc'],axis=1)\n",
    "    aggregates['train_acc'] = np.mean(data['train_acc'],axis=1)\n",
    "    aggregates['test_loss'] = np.mean(data['test_loss'],axis=1)\n",
    "    aggregates['train_loss'] = np.mean(data['train_loss'],axis=1)\n",
    "    aggregates['gap'] = np.mean(data['gap'],axis=1)\n",
    "\n",
    "    return aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "zero models deleted: 15\n",
      "10\n",
      "zero models deleted: 15\n",
      "20\n",
      "zero models deleted: 15\n",
      "5\n",
      "zero models deleted: 15\n",
      "25\n",
      "zero models deleted: 15\n",
      "30\n",
      "zero models deleted: 15\n",
      "40\n",
      "zero models deleted: 15\n",
      "15\n",
      "zero models deleted: 15\n",
      "35\n",
      "zero models deleted: 15\n",
      "50\n",
      "zero models deleted: 15\n",
      "60\n",
      "zero models deleted: 15\n",
      "45\n",
      "zero models deleted: 15\n",
      "65\n",
      "zero models deleted: 15\n",
      "55\n",
      "zero models deleted: 15\n",
      "69\n",
      "zero models deleted: 15\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "optimizer = 'AdaM'\n",
    "\n",
    "input_path = str(sys.path[0][0:-8])+\"/outputs/LilJon-\"+optimizer+\"-\"+dataset\n",
    "epochs = glob.glob(input_path+\"/*\")\n",
    "wanted_epochs = np.arange(0,70,5)\n",
    "wanted_epochs = np.append(wanted_epochs, 69)\n",
    "\n",
    "translation = {'QS':'SQ','QE':'E','spec':'S','fro':'F'}\n",
    "\n",
    "for epoch in epochs:\n",
    "    if int((epoch.split('-')[-1]).split('.')[0]) in wanted_epochs:\n",
    "        print(int((epoch.split('-')[-1]).split('.')[0]))\n",
    "        data = get_data(epoch)\n",
    "        \n",
    "        for key in translation.keys():\n",
    "            plt.plot(data[key+\"_AE\"][1][0],data['test_acc'],'ro')\n",
    "            plt.savefig(str(sys.path[0][0:-8])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/test/LRF\"+(epoch.split('-')[-1]).split('.')[0]+\".png\")\n",
    "            plt.clf()\n",
    "            plt.plot(data[key+\"_BE\"][1][0],data['test_acc'],'ro')\n",
    "            plt.savefig(str(sys.path[0][0:-8])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/test/\"+(epoch.split('-')[-1]).split('.')[0]+\".png\")\n",
    "            plt.clf()\n",
    "            plt.plot(data[key+\"_AE\"][1][0],data['gap'],'ro')\n",
    "            plt.savefig(str(sys.path[0][0:-8])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/gap/LRF\"+(epoch.split('-')[-1]).split('.')[0]+\".png\")\n",
    "            plt.clf()\n",
    "            plt.plot(data[key+\"_BE\"][1][0],data['gap'],'ro')\n",
    "            plt.savefig(str(sys.path[0][0:-8])+\"/results/\"+dataset+\"/\"+optimizer+\"/\"+translation[key]+\"/gap/\"+(epoch.split('-')[-1]).split('.')[0]+\".png\")\n",
    "            plt.clf()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}